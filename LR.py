# import pandas as pd
# import joblib  # â­ ëª¨ë¸ ì €ì¥ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
# from sklearn.model_selection import train_test_split, GridSearchCV
# from sklearn.linear_model import LogisticRegression
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
# from sklearn.preprocessing import StandardScaler  # âœ… ì¶”ê°€: ì •ê·œí™” ë„êµ¬
# from sklearn.pipeline import Pipeline             # âœ… ì¶”ê°€: íŒŒì´í”„ë¼ì¸

# def run_logistic_regression(file_path, exclude_cols, target_col, use_grid_search=False, is_save=False, save_path='log_reg_model.pkl'):
#     """
#     Args:
#         use_grid_search (bool): Trueë©´ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰, Falseë©´ ê¸°ë³¸ ì‹¤í–‰
#         is_save (bool): ëª¨ë¸ ì €ì¥ ì—¬ë¶€ (Trueë©´ ì €ì¥í•¨)
#         save_path (str): ì €ì¥í•  íŒŒì¼ ì´ë¦„
#     """
    
#     # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
#     try:
#         df = pd.read_csv(file_path)
#         print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ì´ {len(df)}ê°œì˜ í–‰ì´ ìˆìŠµë‹ˆë‹¤.")
#     except FileNotFoundError:
#         print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
#         return

#     # 2. ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
#     existing_exclude_cols = [col for col in exclude_cols if col in df.columns]
#     if existing_exclude_cols:
#         df = df.drop(columns=existing_exclude_cols)
#         print(f"â„¹ï¸ ì œì™¸ëœ ì—´: {existing_exclude_cols}")
    
#     # 3. íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ë¶„ë¦¬
#     if target_col not in df.columns:
#         print(f"âŒ ì˜¤ë¥˜: ì˜ˆì¸¡í•  ì—´ '{target_col}'ì´(ê°€) ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
#         return

#     X = df.drop(columns=[target_col])
#     y = df[target_col]

#     # [ì•ˆì „ì¥ì¹˜] ìˆ«ì ë°ì´í„° í™•ì¸
#     non_numeric_cols = X.select_dtypes(exclude=['number']).columns
#     if len(non_numeric_cols) > 0:
#         print(f"âŒ [ì£¼ì˜] ìˆ«ìê°€ ì•„ë‹Œ ì—´ì´ í¬í•¨ë¨: {list(non_numeric_cols)}")
#         return

#     # 4. ë°ì´í„° ë¶„ë¦¬
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#     # ==================================================
#     # [1] í•™ìŠµ ëª¨ë“œ ì„ íƒ (Pipeline ì ìš©)
#     # ==================================================
#     model = None
    
    

#     if use_grid_search:
#         print("\nğŸ” [ëª¨ë“œ: ê·¸ë¦¬ë“œ ì„œì¹˜ ON] ì •ê·œí™” í¬í•¨ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰ ì¤‘...")
        
#         # âœ… íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (ìŠ¤ì¼€ì¼ëŸ¬ -> ë¡œì§€ìŠ¤í‹± íšŒê·€)
#         pipe = Pipeline([
#             ('scaler', StandardScaler()),       # 1ë‹¨ê³„: ì •ê·œí™”
#             ('clf', LogisticRegression(max_iter=1000)) # 2ë‹¨ê³„: ëª¨ë¸
#         ])

#         # âœ… íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì ‘ê·¼ë²•: 'ì´ë¦„__íŒŒë¼ë¯¸í„°' (ì–¸ë”ë°” 2ê°œ)
#         param_grid = {
#             'clf__C': [0.01, 0.1, 1, 10, 100], 
#             'clf__solver': ['lbfgs', 'liblinear'] 
#         }

#         # Grid Search ì‹¤í–‰
#         grid = GridSearchCV(pipe, param_grid, cv=3, verbose=1)
#         grid.fit(X_train, y_train)
        
#         model = grid
#         print(f"ğŸ‰ ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°: {grid.best_params_}")
        
#     else:
#         print("\nğŸš€ [ëª¨ë“œ: ê·¸ë¦¬ë“œ ì„œì¹˜ OFF] ì •ê·œí™” ì ìš© í›„ ê¸°ë³¸ ì„¤ì • ì‹¤í–‰...")
        
#         # âœ… ê¸°ë³¸ ì‹¤í–‰ë„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¶ìŒ
#         model = Pipeline([
#             ('scaler', StandardScaler()), 
#             ('clf', LogisticRegression(max_iter=1000))
#         ])
#         model.fit(X_train, y_train)

#     # 5. ì˜ˆì¸¡ ë° í‰ê°€
#     # (ëª¨ë¸ ì•ˆì— ìŠ¤ì¼€ì¼ëŸ¬ê°€ ë“¤ì–´ìˆì–´ì„œ, X_testë¥¼ ê·¸ëŒ€ë¡œ ë„£ì–´ë„ ì•Œì•„ì„œ ì •ê·œí™” í›„ ì˜ˆì¸¡í•¨)
#     y_pred = model.predict(X_test)

#     # ê²°ê³¼ ì¶œë ¥
#     print("\n" + "="*40)
#     print(f"ğŸ† ëª¨ë¸ ì •í™•ë„ (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
#     print("="*40)
#     print("\n[ë¶„ë¥˜ ë³´ê³ ì„œ]")
#     print(classification_report(y_test, y_pred))
    
#     print("\n[í˜¼ë™ í–‰ë ¬ (Confusion Matrix)]")
#     cm = confusion_matrix(y_test, y_pred)
#     tn, fp, fn, tp = cm.ravel()
#     print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

#     # ==================================================
#     # [2] ì €ì¥ ê¸°ëŠ¥ (Trueì¼ ë•Œë§Œ ì €ì¥)
#     # ==================================================
#     if is_save:
#         joblib.dump(model, save_path)
#         print(f"\nğŸ’¾ [ì €ì¥ ì™„ë£Œ] ì •ê·œí™” ê¸°ëŠ¥ì´ í¬í•¨ëœ ëª¨ë¸ì´ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
#     else:
#         print("\nğŸ“¢ [ì•Œë¦¼] ëª¨ë¸ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì €ì¥ì„ ì›í•˜ë©´ is_save=True ë¡œ ì„¤ì •í•˜ì„¸ìš”)")
    
#     return model

# # ==========================================
# # âš™ï¸ ì‹¤í–‰ ì„¤ì •
# # ==========================================

# # 1. íŒŒì¼ ë° ì»¬ëŸ¼ ì„¤ì •
# input_file = 'mimic_ver_1_0.csv' 
# columns_to_exclude = ['subject_id', 'hadm_id', 'stay_id'] 
# target_column = 'outcome_icu_exit_3d' 

# # 2. ê¸°ëŠ¥ ìŠ¤ìœ„ì¹˜
# is_grid_search_on = True

# # 3. ì €ì¥ ì„¤ì •
# is_save_model = False       
# save_file_name = 'LR_model_1.pkl' 

# # ì‹¤í–‰
# run_logistic_regression(
#     input_file, 
#     columns_to_exclude, 
#     target_column, 
#     use_grid_search=is_grid_search_on,
#     is_save=is_save_model,
#     save_path=save_file_name
# )

import pandas as pd
import joblib  # â­ ëª¨ë¸ ì €ì¥ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

def run_logistic_regression_advanced(file_path, exclude_cols, target_col, use_grid_search=False, is_save=False, save_path='log_reg_model.pkl'):
    
    # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        df = pd.read_csv(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ì´ {len(df)}ê°œì˜ í–‰ì´ ìˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
    existing_exclude_cols = [col for col in exclude_cols if col in df.columns]
    if existing_exclude_cols:
        df = df.drop(columns=existing_exclude_cols)
    
    # 3. ë°ì´í„° ë¶„ë¦¬
    if target_col not in df.columns:
        print(f"âŒ ì˜¤ë¥˜: '{target_col}' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    X = df.drop(columns=[target_col])
    y = df[target_col]

    # ìˆ«ì ë°ì´í„° í™•ì¸
    non_numeric_cols = X.select_dtypes(exclude=['number']).columns
    if len(non_numeric_cols) > 0:
        print(f"âŒ [ì£¼ì˜] ìˆ«ìê°€ ì•„ë‹Œ ì—´ì´ í¬í•¨ë¨: {list(non_numeric_cols)}")
        return

    # 4. Train/Test ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # ==================================================
    # [1] í•™ìŠµ ë° ìµœì í™” (Pipeline ì ìš©)
    # ==================================================
    
    # ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ (ìŠ¤ì¼€ì¼ëŸ¬ + ë¡œì§€ìŠ¤í‹±)
    pipe = Pipeline([
        ('scaler', StandardScaler()), 
        ('clf', LogisticRegression(max_iter=5000)) # ë°˜ë³µ íšŸìˆ˜ ë„‰ë„‰íˆ
    ])

    model = None

    if use_grid_search:
        print("\nğŸ”¥ [ëª¨ë“œ: ê°•ë ¥í•œ ê·¸ë¦¬ë“œ ì„œì¹˜ ON] ìµœì ì˜ íŒŒë¼ë¯¸í„°(L1, L2, ê°€ì¤‘ì¹˜) íƒìƒ‰ ì¤‘...")
        
        # ğŸ’¡ [í•µì‹¬] íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬í•˜ì—¬ 'ë˜ëŠ” ì¡°í•©'ë¼ë¦¬ë§Œ ë¬¶ìŒ
        param_grid = [
            # Case 1: L2 ê·œì œ (ì¼ë°˜ì ì¸ Ridge) - lbfgs, liblinear ë‘˜ ë‹¤ ê°€ëŠ¥
            {
                'clf__penalty': ['l2'],
                'clf__solver': ['lbfgs', 'liblinear'],
                'clf__C': [0.01, 0.1, 1, 10, 100],  # ê·œì œ ê°•ë„
                'clf__class_weight': [None, 'balanced'] # â­ ë°ì´í„° ë¶ˆê· í˜• í•´ê²°ì˜ í•µì‹¬
            },
            # Case 2: L1 ê·œì œ (ë³€ìˆ˜ ì„ íƒ ê¸°ëŠ¥ Lasso) - liblinearë§Œ ê°€ëŠ¥
            {
                'clf__penalty': ['l1'],
                'clf__solver': ['liblinear'], 
                'clf__C': [0.01, 0.1, 1, 10, 100],
                'clf__class_weight': [None, 'balanced']
            }
        ]

        # n_jobs=-1: ì»´í“¨í„°ì˜ ëª¨ë“  CPU ì½”ì–´ë¥¼ ì¨ì„œ ì†ë„ í–¥ìƒ
        grid = GridSearchCV(pipe, param_grid, cv=5, verbose=1, n_jobs=-1, scoring='accuracy')
        grid.fit(X_train, y_train)
        
        model = grid
        print(f"\nğŸ‰ ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°: {grid.best_params_}")
        print(f"   (ìµœê³  ì ìˆ˜: {grid.best_score_:.4f})")
        
    else:
        print("\nğŸš€ [ëª¨ë“œ: ê·¸ë¦¬ë“œ ì„œì¹˜ OFF] 'balanced' ëª¨ë“œë¡œ ê¸°ë³¸ ì‹¤í–‰...")
        
        # ê¸°ë³¸ ì‹¤í–‰ì´ì–´ë„ ì„±ëŠ¥ì„ ìœ„í•´ class_weight='balanced'ëŠ” ì¼œì¤ë‹ˆë‹¤.
        model = Pipeline([
            ('scaler', StandardScaler()), 
            ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))
        ])
        model.fit(X_train, y_train)

    # 5. ì˜ˆì¸¡ ë° í‰ê°€
    y_pred = model.predict(X_test)

    print("\n" + "="*40)
    print(f"ğŸ† ëª¨ë¸ ì •í™•ë„ (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
    print("="*40)
    print("\n[ë¶„ë¥˜ ë³´ê³ ì„œ]")
    print(classification_report(y_test, y_pred))
    
    print("\n[í˜¼ë™ í–‰ë ¬ (Confusion Matrix)]")
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

    # ì €ì¥
    if is_save:
        joblib.dump(model, save_path)
        print(f"\nğŸ’¾ [ì €ì¥ ì™„ë£Œ] '{save_path}'")
    
    return model

# ==========================================
# âš™ï¸ ì‹¤í–‰ ì„¤ì •
# ==========================================

input_file = 'mimic_ver_1_0.csv' 
columns_to_exclude = ['subject_id', 'hadm_id', 'stay_id'] 
target_column = 'outcome_icu_exit_3d' 

# Trueë¡œ ì„¤ì •í•˜ì—¬ ê°•ë ¥í•œ íƒìƒ‰ ì‹œì‘!
run_logistic_regression_advanced(
    input_file, 
    columns_to_exclude, 
    target_column, 
    use_grid_search=True, 
    is_save=True,
    save_path='LR_model_2.pkl'
)
