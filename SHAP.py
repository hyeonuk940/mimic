import pandas as pd
import joblib
import shap
import matplotlib.pyplot as plt
import numpy as np
import warnings
from tqdm import tqdm  # â­ ì§„í–‰ë°” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

# ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

def run_unified_shap_with_progress(model_path, data_path, exclude_cols, target_col):
    print(f"\nğŸ“‚ [1] ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘... ({model_path})")
    try:
        loaded_object = joblib.load(model_path)
    except FileNotFoundError:
        print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. ëª¨ë¸ ì¶”ì¶œ
    if hasattr(loaded_object, 'best_estimator_'):
        main_model = loaded_object.best_estimator_
    else:
        main_model = loaded_object

    # 2. ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“‚ [2] ë°ì´í„° ë¡œë“œ ì¤‘... ({data_path})")
    df = pd.read_csv(data_path)
    
    existing_exclude = [c for c in exclude_cols if c in df.columns]
    df = df.drop(columns=existing_exclude)
    
    if target_col in df.columns:
        X = df.drop(columns=[target_col])
    else:
        X = df
    
    # ì „ì²˜ë¦¬
    import re
    X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))
    X = X.select_dtypes(include=['number'])
    
    # 3. íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬
    final_estimator = main_model
    X_transformed = X

    if isinstance(main_model, Pipeline):
        print("   â„¹ï¸ Pipeline ê°ì§€ -> ìŠ¤ì¼€ì¼ëŸ¬ ì ìš© ì¤‘...")
        final_estimator = main_model.steps[-1][1] 
        preprocessor = Pipeline(main_model.steps[:-1])
        X_transformed_array = preprocessor.transform(X)
        X_transformed = pd.DataFrame(X_transformed_array, columns=X.columns)
    
    # 4. SHAP ë¶„ì„ (ì§„í–‰ë°” ì¶”ê°€ë¨)
    print(f"ğŸ¤– [3] ê°ì§€ëœ ëª¨ë¸ íƒ€ì…: {type(final_estimator).__name__}")
    print("ğŸ“Š SHAP ê°’ ê³„ì‚° ì‹œì‘ (ì§„í–‰ë°”ê°€ í‘œì‹œë©ë‹ˆë‹¤)...")

    explainer = None
    shap_values_list = [] # ê²°ê³¼ë¥¼ ëª¨ì„ ë¦¬ìŠ¤íŠ¸

    try:
        # A. íŠ¸ë¦¬ ëª¨ë¸ (RF, XGB, LGBM)
        if isinstance(final_estimator, (RandomForestClassifier, XGBClassifier, LGBMClassifier)):
            # ì†ë„ë¥¼ ìœ„í•´ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ 2000ê°œë§Œ ìƒ˜í”Œë§ (ì›í•˜ë©´ ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)
            if len(X_transformed) > 2000:
                print("   âš¡ (ì†ë„ ìµœì í™”) ë°ì´í„° 2,000ê°œë§Œ ìƒ˜í”Œë§í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤.")
                X_transformed = X_transformed.sample(4000, random_state=42)

            explainer = shap.TreeExplainer(final_estimator)
            
            # â­ [í•µì‹¬] ë°ì´í„°ë¥¼ 100ê°œì”© ìª¼ê°œì„œ(Batch) ê³„ì‚°í•˜ë©° ì§„í–‰ë°” í‘œì‹œ
            batch_size = 100
            # ë°ì´í„°ë¥¼ 100ê°œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ”
            batches = [X_transformed[i:i + batch_size] for i in range(0, X_transformed.shape[0], batch_size)]
            
            print(f"   ğŸš€ ì´ {len(batches)}ê°œì˜ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            
            for batch in tqdm(batches, desc="SHAP ê³„ì‚° ì¤‘"):
                # ë¶€ë¶„ ê³„ì‚°
                batch_shap = explainer.shap_values(batch, check_additivity=False)
                
                # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸(ì´ì§„ë¶„ë¥˜)ë©´ 1ë²ˆ í´ë˜ìŠ¤ë§Œ ê°€ì ¸ì˜´
                if isinstance(batch_shap, list) and len(batch_shap) == 2:
                    batch_shap = batch_shap[1]
                
                shap_values_list.append(batch_shap)

        # B. ì„ í˜• ëª¨ë¸ (ì›Œë‚™ ë¹¨ë¼ì„œ ë°°ì¹˜ ë¶ˆí•„ìš”í•˜ì§€ë§Œ êµ¬ì¡° í†µì¼)
        elif isinstance(final_estimator, (LogisticRegression, LinearSVC)):
            explainer = shap.LinearExplainer(final_estimator, X_transformed, feature_perturbation="interventional")
            
            # í•œë°©ì— ê³„ì‚° (ì›Œë‚™ ë¹ ë¦„)
            print("   ğŸš€ ì„ í˜• ëª¨ë¸ì€ ìˆœì‹ê°„ì— ê³„ì‚°ë©ë‹ˆë‹¤.")
            batch_shap = explainer.shap_values(X_transformed)
            shap_values_list.append(batch_shap)

        # C. SVM ë° ê¸°íƒ€ (KernelExplainer)
        else:
            print("   âš ï¸ KernelExplainer ì§„ì…")
            if hasattr(final_estimator, "predict_proba"):
                pred_func = final_estimator.predict_proba
                link_type = "identity"
            else:
                pred_func = final_estimator.decision_function
                link_type = "identity"

            # KernelExplainerëŠ” ë„ˆë¬´ ëŠë ¤ì„œ 50ê°œë§Œ ìƒ˜í”Œë§ (ì§„í–‰ë°”ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ì§€ì› ì•ˆë¨)
            print("   âš ï¸ SVMì€ ì§„í–‰ë°” í‘œì‹œê°€ ì–´ë µìŠµë‹ˆë‹¤. (50ê°œ ìƒ˜í”Œë§ ê³„ì‚° ì¤‘...)")
            X_summary = shap.sample(X_transformed, 50) 
            explainer = shap.KernelExplainer(pred_func, X_summary, link=link_type)
            
            # ì „ì²´ ë°ì´í„° ê³„ì‚°
            shap_values = explainer.shap_values(X_transformed)
            if isinstance(shap_values, list) and len(shap_values) == 2:
                shap_values = shap_values[1]
            shap_values_list.append(shap_values)

        # ìª¼ê°œì„œ ê³„ì‚°í•œ ê²°ê³¼ í•©ì¹˜ê¸°
        if shap_values_list:
            shap_values = np.vstack(shap_values_list)
        else:
            return

    except Exception as e:
        print(f"âŒ SHAP ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    # 5. ì‹œê°í™”
    print("\nğŸ“ˆ [1] SHAP ìš”ì•½ ì°¨íŠ¸ (Summary Plot)")
    plt.figure()
    shap.summary_plot(shap_values, X_transformed, show=False)
    plt.title(f"SHAP Summary: {type(final_estimator).__name__}", fontsize=12)
    plt.tight_layout()
    plt.show()

    print("\nğŸ“Š [2] ì¤‘ìš”ë„ ìˆœìœ„ ì°¨íŠ¸ (Bar Plot)")
    plt.figure()
    shap.summary_plot(shap_values, X_transformed, plot_type="bar", show=False)
    plt.title(f"Feature Importance: {type(final_estimator).__name__}", fontsize=12)
    plt.tight_layout()
    plt.show()

# ==========================================
# âš™ï¸ ì‹¤í–‰ ì„¤ì •
# ==========================================

target_model_file = 'XGBoost_model_1.pkl' 
input_file = 'mimic_ver_1_0.csv' 
columns_to_exclude = ['subject_id', 'hadm_id', 'stay_id'] 
target_column = 'outcome_icu_exit_3d' 

# ì‹¤í–‰
run_unified_shap_with_progress(target_model_file, input_file, columns_to_exclude, target_column)