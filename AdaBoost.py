import pandas as pd
import joblib
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline


def run_adaboost_advanced(file_path, exclude_cols, target_col, use_grid_search=False, is_save=False,
                          save_path='adaboost_model.pkl'):
    # 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        df = pd.read_csv(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ì´ {len(df)}ê°œì˜ í–‰ì´ ìˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
    existing_exclude_cols = [col for col in exclude_cols if col in df.columns]
    if existing_exclude_cols:
        df = df.drop(columns=existing_exclude_cols)

    # 3. ë°ì´í„° ë¶„ë¦¬
    X = df.drop(columns=[target_col])
    y = df[target_col]

    # ìˆ«ì ë°ì´í„° í™•ì¸
    non_numeric_cols = X.select_dtypes(exclude=['number']).columns
    if len(non_numeric_cols) > 0:
        print(f"âŒ [ì£¼ì˜] ìˆ«ìê°€ ì•„ë‹Œ ì—´ì´ í¬í•¨ë¨: {list(non_numeric_cols)}")
        return

    # 4. Train/Test ë¶„ë¦¬ (random_state=42 ìœ ì§€)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # ==================================================
    # [1] í•™ìŠµ ë° ìµœì í™” (Pipeline ì ìš©)
    # ==================================================
    # AdaBoostëŠ” íŠ¸ë¦¬ ê¸°ë°˜ì´ë¼ í•„ìˆ˜ì ì´ì§€ëŠ” ì•Šìœ¼ë‚˜,
    # ì¼ê´€ì„±ì„ ìœ„í•´ StandardScalerë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', AdaBoostClassifier(
            estimator=DecisionTreeClassifier(max_depth=1),  # ê¸°ë³¸ í•™ìŠµê¸°: ìŠ¤í…€í”„
            random_state=42,
            algorithm='SAMME'  # ìµœì‹  ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ ëª…ì‹œì  ì§€ì •
        ))
    ])

    model = None

    if use_grid_search:
        print("\nâš¡ [ëª¨ë“œ: ê·¸ë¦¬ë“œ ì„œì¹˜ ON] AdaBoost ìµœì ì˜ ë°˜ë³µ íšŸìˆ˜ ë° í•™ìŠµë¥  íƒìƒ‰ ì¤‘...")

        param_grid = {
            'clf__n_estimators': [50, 100, 200, 500],  # ìƒì„±í•  ì•½í•œ í•™ìŠµê¸° ìˆ˜
            'clf__learning_rate': [0.01, 0.1, 1.0],  # í•™ìŠµë¥  (ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ê°•ë„)
            'clf__estimator__max_depth': [1, 2]  # ê°œë³„ ë‚˜ë¬´ì˜ ê¹Šì´ (ë³´í†µ 1~2ê°€ ì ë‹¹)
        }

        # cv=5ë¡œ K-fold ì ìš©
        grid = GridSearchCV(pipe, param_grid, cv=5, verbose=1, n_jobs=-1, scoring='accuracy')
        grid.fit(X_train, y_train)

        model = grid
        print(f"\nğŸ‰ ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°: {grid.best_params_}")
        print(f"   (ìµœê³  ì ìˆ˜: {grid.best_score_:.4f})")

    else:
        print("\nğŸš€ [ëª¨ë“œ: ê·¸ë¦¬ë“œ ì„œì¹˜ OFF] ê¸°ë³¸ ì„¤ì •(50ê°œ ë‚˜ë¬´)ìœ¼ë¡œ ì‹¤í–‰...")
        model = pipe
        model.fit(X_train, y_train)

    # 5. ì˜ˆì¸¡ ë° í‰ê°€
    y_pred = model.predict(X_test)

    print("\n" + "=" * 40)
    print(f"ğŸ† AdaBoost ì •í™•ë„ (Accuracy): {accuracy_score(y_test, y_pred):.4f}")
    print("=" * 40)
    print("\n[ë¶„ë¥˜ ë³´ê³ ì„œ]")
    print(classification_report(y_test, y_pred))

    print("\n[í˜¼ë™ í–‰ë ¬ (Confusion Matrix)]")
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")

    # ì €ì¥
    if is_save:
        joblib.dump(model, save_path)
        print(f"\nğŸ’¾ [ì €ì¥ ì™„ë£Œ] '{save_path}'")

    return model


# ==========================================
# âš™ï¸ ì‹¤í–‰ ì„¤ì •
# ==========================================
input_file = 'mimic_ver_1_0.csv'
columns_to_exclude = ['subject_id', 'hadm_id', 'stay_id']
target_column = 'outcome_icu_exit_3d'

run_adaboost_advanced(
    input_file,
    columns_to_exclude,
    target_column,
    use_grid_search=True,
    is_save=True,
    save_path='AdaBoost_model_1.pkl'
)